{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488b2439-75a6-4410-b182-d75a6e2bd801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "25-07-08 15:45:39 - Directory C:\\Users\\storm\\.deepface has been created\n",
      "25-07-08 15:45:39 - Directory C:\\Users\\storm\\.deepface\\weights has been created\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d122-de23-4ebe-948f-4ad1a3a784b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-07-08 16:49:59 - 🔗 vgg_face_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5 to C:\\Users\\storm\\.deepface\\weights\\vgg_face_weights.h5...\n"
     ]
    }
   ],
   "source": [
    "model = DeepFace.build_model(\"VGG-Face\")\n",
    "result = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76097d1-5206-46ce-8be6-2a9cf9fcf316",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'deepface.modules.modeling' has no attribute 'build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m objs = \u001b[43mDeepFace\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m  \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg1.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgender\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrace\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43memotion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\DeepFace.py:259\u001b[39m, in \u001b[36manalyze\u001b[39m\u001b[34m(img_path, actions, enforce_detection, detector_backend, align, expand_percentage, silent, anti_spoofing)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manalyze\u001b[39m(\n\u001b[32m    169\u001b[39m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, IO[\u001b[38;5;28mbytes\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m], List[np.ndarray], List[IO[\u001b[38;5;28mbytes\u001b[39m]]],\n\u001b[32m    170\u001b[39m     actions: Union[\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m] = (\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrace\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    177\u001b[39m ) -> Union[List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], List[List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]]:\n\u001b[32m    178\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[33;03m    Analyze facial attributes such as age, gender, emotion, and race in the provided image.\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m            - 'white': Confidence score for White ethnicity.\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdemography\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\modules\\demography.py:146\u001b[39m, in \u001b[36manalyze\u001b[39m\u001b[34m(img_path, actions, enforce_detection, detector_backend, align, expand_percentage, silent, anti_spoofing)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m    144\u001b[39m resp_objects = []\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m img_objs = \u001b[43mdetection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_obj \u001b[38;5;129;01min\u001b[39;00m img_objs:\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m anti_spoofing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img_obj.get(\u001b[33m\"\u001b[39m\u001b[33mis_real\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\modules\\detection.py:115\u001b[39m, in \u001b[36mextract_faces\u001b[39m\u001b[34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing, max_faces)\u001b[39m\n\u001b[32m    113\u001b[39m     face_objs = [DetectedFace(img=img, facial_area=base_region, confidence=\u001b[32m0\u001b[39m)]\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     face_objs = \u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_faces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_faces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\modules\\detection.py:254\u001b[39m, in \u001b[36mdetect_faces\u001b[39m\u001b[34m(detector_backend, img, align, expand_percentage, max_faces)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03mDetect face(s) from a given image\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m \u001b[33;03m    - confidence (float): The confidence score associated with the detected face.\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m height, width, _ = img.shape\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m face_detector: Detector = \u001b[43mmodeling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m(\n\u001b[32m    255\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mface_detector\u001b[39m\u001b[33m\"\u001b[39m, model_name=detector_backend\n\u001b[32m    256\u001b[39m )\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# validate expand percentage score\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expand_percentage < \u001b[32m0\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'deepface.modules.modeling' has no attribute 'build_model'"
     ]
    }
   ],
   "source": [
    "objs = DeepFace.analyze(\n",
    "  img_path = \"img1.jpg\", actions = ['age', 'gender', 'race', 'emotion']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b2c78e-0449-4e57-ba31-fd8c6a301c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'deepface.modules.modeling' has no attribute 'build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m detector = backends[\u001b[32m3\u001b[39m]\n\u001b[32m      7\u001b[39m align = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m obj = \u001b[43mDeepFace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg1.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg2.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m dfs = DeepFace.find(\n\u001b[32m     14\u001b[39m   img_path = \u001b[33m\"\u001b[39m\u001b[33mimg.jpg\u001b[39m\u001b[33m\"\u001b[39m, db_path = \u001b[33m\"\u001b[39m\u001b[33mmy_db\u001b[39m\u001b[33m\"\u001b[39m, detector_backend = detector, align = align\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m embedding_objs = DeepFace.represent(\n\u001b[32m     18\u001b[39m   img_path = \u001b[33m\"\u001b[39m\u001b[33mimg.jpg\u001b[39m\u001b[33m\"\u001b[39m, detector_backend = detector, align = align\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\DeepFace.py:152\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify\u001b[39m(\n\u001b[32m     71\u001b[39m     img1_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, IO[\u001b[38;5;28mbytes\u001b[39m], List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m     72\u001b[39m     img2_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, IO[\u001b[38;5;28mbytes\u001b[39m], List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     83\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     84\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    Verify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    149\u001b[39m \u001b[33;03m        - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mverification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\modules\\verification.py:103\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mVerify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m \u001b[33;03m    - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m tic = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m model: FacialRecognition = \u001b[43mmodeling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m(\n\u001b[32m    104\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mfacial_recognition\u001b[39m\u001b[33m\"\u001b[39m, model_name=model_name\n\u001b[32m    105\u001b[39m )\n\u001b[32m    106\u001b[39m dims = model.output_shape\n\u001b[32m    108\u001b[39m no_facial_area = {\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mright_eye\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    115\u001b[39m }\n",
      "\u001b[31mAttributeError\u001b[39m: module 'deepface.modules.modeling' has no attribute 'build_model'"
     ]
    }
   ],
   "source": [
    "backends = [\n",
    "    'opencv', 'ssd', 'dlib', 'mtcnn', 'fastmtcnn',\n",
    "    'retinaface', 'mediapipe', 'yolov8', 'yolov11s',\n",
    "    'yolov11n', 'yolov11m', 'yunet', 'centerface',\n",
    "]\n",
    "detector = backends[3]\n",
    "align = True\n",
    "\n",
    "obj = DeepFace.verify(\n",
    "  img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", detector_backend = detector, align = align\n",
    ")\n",
    "\n",
    "dfs = DeepFace.find(\n",
    "  img_path = \"img.jpg\", db_path = \"my_db\", detector_backend = detector, align = align\n",
    ")\n",
    "\n",
    "embedding_objs = DeepFace.represent(\n",
    "  img_path = \"img.jpg\", detector_backend = detector, align = align\n",
    ")\n",
    "\n",
    "demographies = DeepFace.analyze(\n",
    "  img_path = \"img4.jpg\", detector_backend = detector, align = align\n",
    ")\n",
    "\n",
    "face_objs = DeepFace.extract_faces(\n",
    "  img_path = \"img.jpg\", detector_backend = detector, align = align\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2846013c-2204-4dcf-b6f6-48070af66b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.94\n"
     ]
    }
   ],
   "source": [
    "import deepface\n",
    "print(deepface.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c44c0d-91cb-43d3-8569-df88d2ecd25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-07-08 16:26:54 - 🔗 facenet_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5 to C:\\Users\\storm\\.deepface\\weights\\facenet_weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\n",
      "To: C:\\Users\\storm\\.deepface\\weights\\facenet_weights.h5\n",
      " 46%|████████████████████████████████████████████████████                                                             | 42.5M/92.2M [19:42<47:30, 17.4kB/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "⛓️‍💥 An exception occurred while downloading facenet_weights.h5 from https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5. Consider downloading it manually to C:\\Users\\storm\\.deepface\\weights\\facenet_weights.h5.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIncompleteRead\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:779\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:925\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    916\u001b[39m         \u001b[38;5;28mself\u001b[39m.enforce_content_length\n\u001b[32m    917\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length_remaining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    923\u001b[39m         \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[32m    924\u001b[39m         \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m._fp_bytes_read, \u001b[38;5;28mself\u001b[39m.length_remaining)\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read1 \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    927\u001b[39m     (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length_remaining == \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[32m    928\u001b[39m ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    931\u001b[39m     \u001b[38;5;66;03m# `http.client.HTTPResponse`, so we close it here.\u001b[39;00m\n\u001b[32m    932\u001b[39m     \u001b[38;5;66;03m# See https://github.com/python/cpython/issues/113199\u001b[39;00m\n",
      "\u001b[31mIncompleteRead\u001b[39m: IncompleteRead(42658494 bytes read, 49532322 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:1008\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) < amt \u001b[38;5;129;01mand\u001b[39;00m data:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;66;03m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[32m   1006\u001b[39m     \u001b[38;5;66;03m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[32m   1007\u001b[39m     \u001b[38;5;66;03m# it one byte at a time\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m     decoded_data = \u001b[38;5;28mself\u001b[39m._decode(data, decode_content, flush_decoder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:903\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\urllib3\\response.py:803\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    802\u001b[39m         arg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConnection broken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(arg, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection broken: IncompleteRead(42658494 bytes read, 49532322 more expected)', IncompleteRead(42658494 bytes read, 49532322 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mChunkedEncodingError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\commons\\weight_utils.py:55\u001b[39m, in \u001b[36mdownload_weights_if_necessary\u001b[39m\u001b[34m(file_name, source_url, compress_type)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compress_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mgdown\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m compress_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m compress_type \u001b[38;5;129;01min\u001b[39;00m ALLOWED_COMPRESS_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\gdown\\download.py:368\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    367\u001b[39m t_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda3\\envs\\DeepFace\\Lib\\site-packages\\requests\\models.py:822\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mChunkedEncodingError\u001b[39m: ('Connection broken: IncompleteRead(42658494 bytes read, 49532322 more expected)', IncompleteRead(42658494 bytes read, 49532322 more expected))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 构建模型（以Facenet为例）\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mDeepFace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFacenet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\DeepFace.py:67\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(model_name, task)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, task: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mfacial_recognition\u001b[39m\u001b[33m\"\u001b[39m) -> Any:\n\u001b[32m     52\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    This function builds a pre-trained model\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m \u001b[33;03m        built_model\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodeling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\modules\\modeling.py:101\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(task, model_name)\u001b[39m\n\u001b[32m     99\u001b[39m model = models[task].get(model_name)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     cached_models[task][model_name] = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid model_name passed - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\models\\facial_recognition\\Facenet.py:59\u001b[39m, in \u001b[36mFaceNet128dClient.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mload_facenet128d_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name = \u001b[33m\"\u001b[39m\u001b[33mFaceNet-128d\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_shape = (\u001b[32m160\u001b[39m, \u001b[32m160\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\models\\facial_recognition\\Facenet.py:1676\u001b[39m, in \u001b[36mload_facenet128d_model\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m   1667\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[33;03mConstruct FaceNet-128d model, download weights and then load weights\u001b[39;00m\n\u001b[32m   1669\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1672\u001b[39m \u001b[33;03m    model (Model)\u001b[39;00m\n\u001b[32m   1673\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1674\u001b[39m model = InceptionResNetV1()\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m weight_file = \u001b[43mweight_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_weights_if_necessary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfacenet_weights.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m model = weight_utils.load_model_weights(model=model, weight_file=weight_file)\n\u001b[32m   1681\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\VS Code\\deepface\\deepface\\commons\\weight_utils.py:60\u001b[39m, in \u001b[36mdownload_weights_if_necessary\u001b[39m\u001b[34m(file_name, source_url, compress_type)\u001b[39m\n\u001b[32m     57\u001b[39m         gdown.download(source_url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompress_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, quiet=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     61\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⛓️‍💥 An exception occurred while downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConsider downloading it manually to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# uncompress downloaded file\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compress_type == \u001b[33m\"\u001b[39m\u001b[33mzip\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: ⛓️‍💥 An exception occurred while downloading facenet_weights.h5 from https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5. Consider downloading it manually to C:\\Users\\storm\\.deepface\\weights\\facenet_weights.h5."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████████████████                                                             | 42.5M/92.2M [20:01<47:30, 17.4kB/s]"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "# 构建模型（以Facenet为例）\n",
    "model = DeepFace.build_model(\"Facenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf595916-f3a3-4cc9-8475-ac63c1c58a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
